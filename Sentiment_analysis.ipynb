{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "BoC6EAsdqAhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # Importing all the necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords as Stopwords\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import Logistic Regression\n",
        "from sklearn.metrics import classification_report, log_loss\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "wnqg91oxqI5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "wa9AMpSa9q5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download (\"stopwords\")"
      ],
      "metadata": {
        "id": "HZqmb5PZ9vBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD DATASET"
      ],
      "metadata": {
        "id": "867rwRYFgXaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dataset = pd.read_csv(\"\")\n",
        "reviews_dataset.head(10)"
      ],
      "metadata": {
        "id": "XWwsuUhBglwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dataset.info()"
      ],
      "metadata": {
        "id": "goL7DAGegyFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "Bizwlo7Ig1mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dataset.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "jpGCNJdbg4iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dataset.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "cHoJ0SOuhEaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dataset.info()"
      ],
      "metadata": {
        "id": "iSzg3F1_hYZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLEANING RATING COLUMN"
      ],
      "metadata": {
        "id": "Yn2RvaD6hPfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dataset"
      ],
      "metadata": {
        "id": "4CpJJm9RhSsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_dataset[\"Rating\"] = reviews_dataset[\"Rating\"].apply(lambda x : re.findall(\"\\d\",x)[0])"
      ],
      "metadata": {
        "id": "QApdNMaYhcQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Mapping positive, neutral and negative to rating values\n",
        "2\n",
        "3 reviews_dataset[\"Sentiment\"] = reviews_dataset [\"Rating\"].map({\"5\":\"Positive\", \"4\":\"Positive\", \"3\":\"Neutral\", \"2\":\"Negative\", \"1\":\"Negative\"}) 4 reviews_dataset"
      ],
      "metadata": {
        "id": "JrIcOmaUp-vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING YEAR OF STAY COLUMN"
      ],
      "metadata": {
        "id": "QVtyHh92p_gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Creating a new column year of stay from our existing column date of stay\n",
        "3 reviews_dataset [ \"Year of stay\"] = reviews_dataset [\"Date of stay\"].apply(lambda x: \"\".join(re.findall (\"\\d\\d\\d\\d\", x))) 4 reviews_dataset"
      ],
      "metadata": {
        "id": "8iuC57M6GEIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING MONTH OF STAY COLUMN"
      ],
      "metadata": {
        "id": "ZwkBj8O7jgjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1# Creating a month of stay column from date of stay column\n",
        "2 reviews dataset[\"Month of stay\"] reviews_dataset[\"Date of stay\"].apply(lambda x: \".join(re.findall(r' (Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:11)?|May Jun(?:e)?|July)?|A 3 reviews dataset"
      ],
      "metadata": {
        "id": "ZI1ExcA8GEnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DROPPING ROWS"
      ],
      "metadata": {
        "id": "qrnUJQiDF-d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Dropping all rows for which year is less than 2018\n",
        "2\n",
        "3 reviews_dataset.drop(reviews_dataset [reviews_dataset [ \"Year of stay\"] < '2018']. index, axis=0, inplace=True)\n",
        "4\n",
        "5\n",
        "6\n",
        "7 # Dropping all neutral sentiment rows\n",
        "8\n",
        "9 reviews_dataset.drop(reviews_dataset [reviews_dataset [\"Sentiment\"]\n",
        "==\n",
        "\"Neutral\"].index, axis=0, inplace=True)"
      ],
      "metadata": {
        "id": "RiDJSUvFGAvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Checking information for the dataset after removing rows\n",
        "2 #After removing reviews before 2018 and neutral sentiment, remaining row number is 8293.\n",
        "3\n",
        "4 reviews_dataset.info()"
      ],
      "metadata": {
        "id": "XZGmsjPAGG8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECKING PERCENTAGE OF SENTIMENT"
      ],
      "metadata": {
        "id": "oYQyl8sVGHKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Checking percentage of each sentiment in our dataset\n",
        "2\n",
        "3 reviews_dataset.Sentiment.value_counts (normalize=True)"
      ],
      "metadata": {
        "id": "VMGSXf7AGnXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Shuffling the dataset\n",
        "2\n",
        "3 reviews_dataset = reviews_dataset.sample(frac = 1)\n",
        "4 reviews_dataset"
      ],
      "metadata": {
        "id": "PC3GiA0dGnln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION TO PREPROCESS THE REVIEW COLUMN"
      ],
      "metadata": {
        "id": "52OkD_5XGnwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 def preprocess_data(text):\n",
        "Returns text after removing numbers, punctuations, urls, emojis, html tags and lowercasing all the words in given text.\n",
        "# removing numbers\n",
        "text = re.sub(r'[^\\w\\s]',, str(text)) # removing punctuations text=\"\".join(x.lower() for x in text.split()) # lower casing the text\n",
        "text = re.sub(r'https?://\\S+|www\\.\\S+\", \", text) # removing urls text = re.sub(r'<.\"?>', '', text) # removing html tags\n",
        "emoji_pattern= re.compile(\"[\"\n",
        "\n",
        "text = re.sub(r'[0-9]+', '', str(text))\n",
        "\n",
        "text = emoji_pattern.sub(r\", text)\n",
        "u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
        "u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols u\"\\U0001F1E0-\\U0001F1FF\" # flags (ios)\n",
        "u\"\\U00002702-\\U00002780\"\n",
        "u\"\\U000024C2-\\U0001F251\"\n",
        "\"]+\", flags=re.UNICODE)\n",
        "text = \".join(x for x in text.split() if x not in stopwords.words('english')) return text"
      ],
      "metadata": {
        "id": "2-B51h74GpOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Applying preprocess_data function to review column\n",
        "2\n",
        "3 reviews_dataset [ \"Preprocessed_reviews\"] = reviews_dataset [ \"Review\"].apply(lambda x: preprocess_data(x)) 4 reviews_dataset"
      ],
      "metadata": {
        "id": "uMChcoLMGp9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING A COLUMN FOR NUMBER OF WORDS IN REVIEW"
      ],
      "metadata": {
        "id": "xQOiWbxwGqGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # Word count\n",
        "2\n",
        "3 reviews_dataset [\"Word_count\"]\n",
        "4 reviews_dataset.head()\n",
        "=\n",
        "reviews_dataset [\"Review\"].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "3mjvAB1QGsQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING A COLUMN FOR NUMBER OF UNIQUE WORDS IN REVIEW"
      ],
      "metadata": {
        "id": "ud6cvXjaGurJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1 # unique Word count\n",
        "2\n",
        "3 reviews_dataset [\"unique_Word_count\"] = reviews_dataset [\"Review\"].apply(lambda x: len(set(str(x).split()))\n",
        "4 reviews_dataset.head()\n"
      ],
      "metadata": {
        "id": "9PhqXFmFGww9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING A COLUMN FOR NUMBER OF STOPWORDS IN REVIEW"
      ],
      "metadata": {
        "id": "NYwzp2P1Gw3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Number of stop words in review\n",
        "\n",
        " stop_words = Stopwords.words ('english')\n",
        " reviews_dataset[\"Stopword_count\"] = reviews_dataset [\"Review\"].apply(lambda x: len([w for w in str(x).lower().split() if w not in stop words])) 5 reviews_dataset.head()"
      ],
      "metadata": {
        "id": "V9FwPHcBGzhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING A COLUMN FOR AVERAGE WORD LENGTH IN A REVIEW"
      ],
      "metadata": {
        "id": "q8hylmyBG098"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mean word length\n",
        "\n",
        "reviews_dataset[\"Mean_word_length\"] = reviews_dataset[\"Review\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "reviews_dataset.head()"
      ],
      "metadata": {
        "id": "xxgdFsyxG1Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING A COLUMN FOR NUMBER OF CHARACTER IN A REVIEW"
      ],
      "metadata": {
        "id": "EF-ORhXUG3fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# char count\n",
        "\n",
        "reviews_dataset[\"char_count\"] = reviews_dataset[\"Review\"].apply(lambda x: len(str(x)))\n",
        "reviews_dataset.head()"
      ],
      "metadata": {
        "id": "59Tsn0jAG4Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING A COLUMN FOR NUMBER OF PUNCTUATION IN A REVIEW"
      ],
      "metadata": {
        "id": "3jtFNo7cG4aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# punctuation count\n",
        "\n",
        "reviews_dataset[\"punctuation_count\"] = reviews_dataset[\"Review\"].apply(lambda x: len([p for p in str(x) if p in string.punctuation]))\n",
        "reviews_dataset.head()"
      ],
      "metadata": {
        "id": "Wo969HUxG6pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXPLORATORY DATA ANALYSIS (EDA)"
      ],
      "metadata": {
        "id": "Yff0_M_1G7gB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PIE CHART"
      ],
      "metadata": {
        "id": "uR7sMI5FG-HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a pie chart showing target distribution in dataset\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "reviews_dataset['Sentiment'].value_counts().plot(kind='pie', autopct=\"%1.1f%%\", startangle=90, fontsize=14, colors=['#27EEA4', '#F37D67']);\n",
        "s.set_ylabel('');\n",
        "s.set_title('Target Distribution in dataset', fontsize=20);"
      ],
      "metadata": {
        "id": "loXRjgGkG_pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-GRAMS"
      ],
      "metadata": {
        "id": "YAh22nYxHnhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for generating ngrams\n",
        "\n",
        "def generate_ngrams(text, n_gram=1):\n",
        "    \"\"\"\n",
        "    Returns ngrams for the given text.\n",
        "\n",
        "    Parameters:\n",
        "    text : for which we want ngrams\n",
        "    n_gram : value for ngram\n",
        "    \"\"\"\n",
        "    token = [token for token in text.lower().split(' ') if token != '' if token not in STOPWORDS]\n",
        "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
        "    return [' '.join(ngram) for ngram in ngrams]"
      ],
      "metadata": {
        "id": "8gsGEWsZHpP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNI-GRAMS"
      ],
      "metadata": {
        "id": "3TlNXkuuHqaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a default dictionary for positive and negative unigrams\n",
        "positive_unigrams = defaultdict(int)\n",
        "negative_unigrams = defaultdict(int)\n",
        "\n",
        "# Number of ngrams we want\n",
        "N = 25\n",
        "\n",
        "# Loop for updating value of positive_unigrams\n",
        "for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment'] == \"Positive\"]:\n",
        "    for word in generate_ngrams(review):\n",
        "        positive_unigrams[word] += 1\n",
        "\n",
        "# Loop for updating value of negative_unigrams\n",
        "for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment'] == \"Negative\"]:\n",
        "    for word in generate_ngrams(review):\n",
        "        negative_unigrams[word] += 1\n",
        "\n",
        "# Creating dataframes using default dictionaries\n",
        "df_positive_unigrams = pd.DataFrame(sorted(positive_unigrams.items(), key=lambda x: x[1], reverse=True))\n",
        "df_negative_unigrams = pd.DataFrame(sorted(negative_unigrams.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(24, 10))\n",
        "plt.tight_layout(pad=4.0)\n",
        "\n",
        "# Plotting positive and negative unigrams dataset\n",
        "sns.despine()\n",
        "sns.barplot(y=df_positive_unigrams[0].values[:N], x=df_positive_unigrams[1].values[:N], ax=axes[0], color='#272EAA')\n",
        "sns.barplot(y=df_negative_unigrams[0].values[:N], x=df_negative_unigrams[1].values[:N], ax=axes[1], color='#F37D67')"
      ],
      "metadata": {
        "id": "GFTN3WXlHq0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "axes[0].set_title(f'Top {N} most common unigrams in Positive Reviews', fontsize=15)\n",
        "axes[1].set_title(f'Top {N} most common unigrams in Negative Reviews', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c3_FAR0RHrza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BI-GRAMS"
      ],
      "metadata": {
        "id": "MY120OwbHr7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a default dictionary for positive and negative bigrams\n",
        "positive_bigrams = defaultdict(int)\n",
        "negative_bigrams = defaultdict(int)\n",
        "\n",
        "# Number of ngrams we want\n",
        "N = 25\n",
        "\n",
        "# Loop for updating values of bigrams in default dictionary\n",
        "for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Positive\"]:\n",
        "    for word in generate_ngrams(review, n_gram=2):\n",
        "        positive_bigrams[word] += 1\n",
        "\n",
        "for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Negative\"]:\n",
        "    for word in generate_ngrams(review, n_gram=2):\n",
        "        negative_bigrams[word] += 1\n",
        "\n",
        "# Creating a dataset using default dictionaries\n",
        "df_positive_bigrams = pd.DataFrame(sorted(positive_bigrams.items(), key=lambda x: x[1], reverse=True))\n",
        "df_negative_bigrams = pd.DataFrame(sorted(negative_bigrams.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(24, 10))\n",
        "plt.tight_layout(pad=4)\n",
        "\n",
        "# Plotting both positive and negative bigrams\n",
        "sns.despine()\n",
        "sns.barplot(x=df_positive_bigrams[1].values[:N], y=df_positive_bigrams[0].values[:N], ax=axes[0], color='#72EEA4')\n",
        "sns.barplot(x=df_negative_bigrams[1].values[:N], y=df_negative_bigrams[0].values[:N], ax=axes[1], color='#F37D67')\n",
        "\n",
        "axes[0].set_title(f'Top {N} most common bigrams in Positive Reviews', fontsize=15)"
      ],
      "metadata": {
        "id": "tGO0lgYQHtkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "axes[0].set_title(f'Top {N} most common bigrams in Positive Reviews', fontsize=15)\n",
        "axes[1].set_title(f'Top {N} most common bigrams in Negative Reviews', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xQFOxtUcHtrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRI-GRAMS"
      ],
      "metadata": {
        "id": "HK4N2a_tHvlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating default dictionary for positive and negative trigrams\n",
        "positive_trigrams = defaultdict(int)\n",
        "negative_trigrams = defaultdict(int)\n",
        "\n",
        "# Number of ngrams we want\n",
        "N = 25\n",
        "\n",
        "# Loop for updating default dictionaries\n",
        "for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Positive\"]:\n",
        "    for word in generate_ngrams(review, n_gram=3):\n",
        "        positive_trigrams[word] += 1\n",
        "\n",
        "for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Negative\"]:\n",
        "    for word in generate_ngrams(review, n_gram=3):\n",
        "        negative_trigrams[word] += 1\n",
        "\n",
        "# Creating a dataframe using dictionaries\n",
        "df_positive_trigrams = pd.DataFrame(sorted(positive_trigrams.items(), key=lambda x: x[1], reverse=True))\n",
        "df_negative_trigrams = pd.DataFrame(sorted(negative_trigrams.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(24, 10))\n",
        "plt.tight_layout(pad=4.0)\n",
        "\n",
        "# Plotting positive and negative trigrams\n",
        "sns.despine()\n",
        "sns.barplot(y = df_positive_trigrams[0].values[:N], x = df_positive_trigrams[1].values[:N], ax=axes[0], color=\"#72EEA4\")\n",
        "sns.barplot(y = df_negative_trigrams[0].values[:N], x = df_negative_trigrams[1].values[:N], ax=axes[1], color=\"#F37D67\")\n",
        "axes[0].set_title('Top N most common trigrams in Positive Reviews', fontsize=15)"
      ],
      "metadata": {
        "id": "gkPVp6ucHwUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "axes[0].set_title(f'Top {N} most common trigrams in Positive Reviews', fontsize=15)\n",
        "axes[1].set_title(f'Top {N} most common trigrams in Negative Reviews', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KPt2Nw59Hwaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BAR PLOT FOR EACH YEAR"
      ],
      "metadata": {
        "id": "3xR2c-K_HwiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting number of reviews for each year\n",
        "\n",
        "plt.figure(figsize = (24, 5))\n",
        "years = ['2018', '2019', '2020', '2021']\n",
        "sns.despine()\n",
        "sns.countplot(x=\"Year of stay\", data=reviews_dataset, order=years, color='#62DCEC');"
      ],
      "metadata": {
        "id": "3UUeEmuwHyma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOTTING WORD COUNT"
      ],
      "metadata": {
        "id": "o22bNwtPHzt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1  Plotting word count for reviews\n",
        "\n",
        "fig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n",
        "\n",
        "sns.despine()\n",
        "sns.histplot(ax=axes[0], x=\"word_count\", data=reviews_dataset[reviews_dataset['Sentiment'] == 'Positive'], kde=True, color=\"#172EE4\")\n",
        "sns.histplot(ax=axes[1], x=\"word_count\", data=reviews_dataset[reviews_dataset['Sentiment'] == 'Negative'], kde=True, color=\"#37067\")\n",
        "\n",
        "axes[0].set_title(\"Positive reviews\", fontsize=16)\n",
        "axes[1].set_title(\"Negative reviews\", fontsize=16)\n",
        "\n",
        "axes[0].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[1].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[0].set_xlabel(\"word count in review\", fontsize=12)\n",
        "axes[1].set_xlabel(\"word count in review\", fontsize=12)\n",
        "\n",
        "fig.suptitle(\"Word count for reviews\", fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mD0e-hmkH1qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOTTING UNIQUE WORD COUNT"
      ],
      "metadata": {
        "id": "VRWwJ7DPH1xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 # Plotting unique word count for reviews\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(24, 6))\n",
        "sns despine()\n",
        "\n",
        "sns.histplot(ax=axes[0], x=\"Unique_word_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Positive'], kde=True, color=\"#72EAE4\")\n",
        "sns.histplot(ax=axes[1], x=\"Unique_word_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Negative'], kde=True, color=\"#F37D67\")\n",
        "\n",
        "axes[0].set_title(\"Positive reviews\", fontsize=16)\n",
        "axes[1].set_title(\"Negative reviews\", fontsize=16)\n",
        "\n",
        "axes[0].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[1].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[0].set_xlabel(\"unique word count in review\", fontsize=12)\n",
        "axes[1].set_xlabel(\"Unique word count in review\", fontsize=12)\n",
        "\n",
        "fig.suptitle(\"Unique word count for reviews\", fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fUKtkggMH3Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOTTING STOP WORD COUNT"
      ],
      "metadata": {
        "id": "lqiH4txSH3cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting stopword count for reviews\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(24, 6))\n",
        "\n",
        "sns.despine()\n",
        "sns.histplot(ax=axes[0], x=\"Stopword_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Positive'], kde=True, color=\"#27EAA4\");\n",
        "sns.histplot(ax=axes[1], x=\"Stopword_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Negative'], kde=True, color=\"#F37D67\");\n",
        "\n",
        "axes[0].set_title(\"Positive reviews\", fontsize=16)\n",
        "axes[1].set_title(\"Negative reviews\", fontsize=16)\n",
        "\n",
        "axes[0].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[1].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[0].set_xlabel(\"Stopword count in review\", fontsize=12)\n",
        "axes[1].set_xlabel(\"Stopword count in review\", fontsize=12)\n",
        "\n",
        "fig.suptitle(\"Stopword count for reviews\", fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mHXBzlRSH48w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOTTING CHARACTER COUNT"
      ],
      "metadata": {
        "id": "FYLIHdQxH6bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 = Plotting character count for reviews\n",
        "fig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n",
        "sns.despine()\n",
        "sns.histplot(ax=axes[0], x=\"Char_count\", data=reviews_dataset[reviews_dataset['sentiment'] == 'Positive'], kde=True, color=\"#72EE44\")\n",
        "sns.histplot(ax=axes[1], x=\"Char_count\", data=reviews_dataset[reviews_dataset['sentiment'] == 'Negative'], kde=True, color=\"#F37D67\")\n",
        "\n",
        "axes[0].set_title(\"Positive reviews\", fontsize=16)\n",
        "axes[1].set_title(\"Negative reviews\", fontsize=16)\n",
        "\n",
        "axes[0].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[1].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "axes[0].set_xlabel(\"Character count in review\", fontsize=12)\n",
        "axes[1].set_xlabel(\"Character count in review\", fontsize=12)\n",
        "\n",
        "fig.suptitle(\"Character count for reviews\", fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZlMHuFGKH680"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOTTING PUNCTUATION COUNT"
      ],
      "metadata": {
        "id": "sR43yyH5H82F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1  # Plotting punctuation count for reviews\n",
        "2  fig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n",
        "3  sns.despine()\n",
        "4  sns.histplot(ax=axes[0], x=\"punctuation_count\", data=reviews_dataset[reviews_dataset['Sentiment'] == 'positive'], kde=True, color=\"#72EEA4\")\n",
        "5  sns.histplot(ax=axes[1], x=\"punctuation_count\", data=reviews_dataset[reviews_dataset['Sentiment'] == 'negative'], kde=True, color=\"#F37D67\")\n",
        "6  axes[0].set_title(\"Positive reviews\", fontsize=16)\n",
        "7  axes[1].set_title(\"Negative reviews\", fontsize=16)\n",
        "8  axes[0].set_xscale('log')\n",
        "9  axes[0].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "10 axes[1].set_ylabel(\"Number of reviews\", fontsize=12)\n",
        "11 axes[0].set_xlabel(\"Punctuation count in review\", fontsize=12)\n",
        "12 axes[1].set_xlabel(\"Punctuation count in review\", fontsize=12)\n",
        "13 fig.suptitle(\"Punctuation count for reviews\", fontsize=20)\n",
        "14 plt.show()"
      ],
      "metadata": {
        "id": "-iWYJ6qqH9Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WORD CLOUD"
      ],
      "metadata": {
        "id": "uDAssxslH9kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD CLOUD FOR POSTIVE REVIEW"
      ],
      "metadata": {
        "id": "hBMKVTXUIAGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a wordcloud for positive reviews\n",
        "\n",
        "positive = \" \".join(review for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment'] == \"Positive\"])\n",
        "wordcloud = WordCloud(background_color='white', stopwords=STOPWORDS, max_words=500, max_font_size=40, random_state=42, colormap='Greens').generate(positive)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.title(\"Most common words in positive reviews\")\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qCASV-WMICn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD CLOUD FOR NEGATIVE REVIEW"
      ],
      "metadata": {
        "id": "y_DGBbeFIDMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting wordcloud for negative reviews\n",
        "negative = ' '.join(review for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment'] == \"negative\"])\n",
        "wordcloud = WordCloud(background_color='white', stopwords=STOPWORDS, max_words=500, max_font_size=40, random_state=42, colormap=\"Reds\").generate(negative)\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.title(\"Most common words in negative reviews\")\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EO4iBOOcIPbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom stop words\n",
        "\n",
        "all_text = \" \".join(list(reviews_dataset[\"Preprocessed_reviews\"]))\n",
        "words = pd.Series(all_text.split(\" \"))\n",
        "frequent_words = words.value_counts()[:20]"
      ],
      "metadata": {
        "id": "dqDU-xVsIPpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using label encoder to encode sentiment column\n",
        "\n",
        "le = LabelEncoder()\n",
        "reviews_dataset['Sentiment'] = le.fit_transform(reviews_dataset['Sentiment'])"
      ],
      "metadata": {
        "id": "lzpAhh3OIRNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = reviews_dataset.iloc[:,0]\n",
        "x"
      ],
      "metadata": {
        "id": "tcswmqsFIRUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = reviews_dataset.iloc[:,3]\n",
        "y"
      ],
      "metadata": {
        "id": "Vk8VIQJHISBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING AND TESTING"
      ],
      "metadata": {
        "id": "mesUVh3hISk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and testing dataset\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y,\n",
        "                                               random_state=42,\n",
        "                                               test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "-nQUwGbAIUQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING AND VALIDATION"
      ],
      "metadata": {
        "id": "vRPqI3DIIVDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and testing dataset\n",
        "xtrain, xval, ytrain, yval = train_test_split(x, y,\n",
        "                                               random_state=42,\n",
        "                                               test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "26umlKk4IWbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL TRAINING"
      ],
      "metadata": {
        "id": "5_X8k3wfIXxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing TfidfVectorizer\n",
        "tfv = TfidfVectorizer(min_df=3, max_features=None, decode_error=\"replace\", preprocessor=preprocess_data,\n",
        "                      strip_accents='unicode', analyzer='word', token_pattern='w(1,)',\n",
        "                      ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
        "                      stop_words='english')\n",
        "\n",
        "# Fitting Tfidf vectorizer to training dataset\n",
        "tfv.fit(list(xtrain))\n",
        "\n",
        "# Transforming the training and validation dataset\n",
        "xtrain_tfv = tfv.transform(xtrain)\n",
        "xval_tfv = tfv.transform(xval)"
      ],
      "metadata": {
        "id": "WJSVG7gGIYcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Initializing XGClassifier\n",
        "xgb = XGClassifier(learning_rate=0.02, n_estimators=600, max_depth=4, subsample=1.0, min_child_weight=1, gamma=0.5, colsample_bytree=0.8, random_state=42)\n",
        "\n",
        "# 3 Fitting xgb on training dataset\n",
        "model = xgb.fit(train_tfv, ytrain)\n",
        "\n",
        "# 7 Making predictions on validation dataset\n",
        "predictions = model.predict_proba(val_tfv)\n",
        "print(f\"logloss: {log_loss(yval, predictions)}\")\n",
        "\n",
        "ypred_xg = model.predict(val_tfv)\n",
        "print(classification_report(yval, ypred_xg))"
      ],
      "metadata": {
        "id": "nYOj5Pj2ia2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL EVALUATION"
      ],
      "metadata": {
        "id": "jy1I3OILiyD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming test dataset using the same tfidf vectoririzer we fit on training dataset\n",
        "\n",
        "xtest_tfv = tfv.transform(xtest)"
      ],
      "metadata": {
        "id": "XT5xVRhNjUU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = xgb.predict(xtest_tfv)\n",
        "p"
      ],
      "metadata": {
        "id": "EHQNpHuUkDkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making prediction on testing dataset\n",
        "\n",
        "predictions = xgb.predict_proba(xtest_tfv)\n",
        "print(\"logloss : %0.3f \" % log_loss(ytest,prediction))\n",
        "ypred_xg = xgb.predict(xtest_tfv)\n",
        "print(classification_report(ytest,ypred_xg))"
      ],
      "metadata": {
        "id": "RZFyykX2kH_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACCURACY"
      ],
      "metadata": {
        "id": "69nRQl_xlIOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(ytest,ypred_xg)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "lYPsFSp7k-bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL PREDICTION"
      ],
      "metadata": {
        "id": "vN-alOl5lNCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [input(\"Enter a review : \")]\n",
        "text_tfv = tfv.transform(text)\n",
        "\n",
        "y_pred = model.predict(text_tfv)\n",
        "\n",
        "#get the predicted sentiment\n",
        "senti = y_pred[0]\n",
        "\n",
        "#interpret the prediction\n",
        "if senti > 0:\n",
        "  print(\"the review is predicted to be positive\")\n",
        "else:\n",
        "  print(\"the review is predicted to be negative\")"
      ],
      "metadata": {
        "id": "XoWdmDoxlHMj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}